{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1M13PrPPAQwA43cCIwuA3uFWsFoPIhpI0","timestamp":1665805283077},{"file_id":"1loSnrEW4XBw6u2WE0c89EGPZjmYbFv8-","timestamp":1658725213429}],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c1e400d73b7d474b997009634e55de6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66cdb1449b2f4543af72123e6e8bc8b8","IPY_MODEL_1f0f52e07e3346589ba9b664d62aa432","IPY_MODEL_8c44164a76344653afb976837f28c827"],"layout":"IPY_MODEL_af9378a1f484417c997d4f0614339043"}},"66cdb1449b2f4543af72123e6e8bc8b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d259ec8fde54f928571a1e09d109ec2","placeholder":"​","style":"IPY_MODEL_fb08c71d29cc481b85e486db1e6774dc","value":"Downloading: 100%"}},"1f0f52e07e3346589ba9b664d62aa432":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01175928d4a4e32aee372a65c237a5b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f46d61dd445a458f9234728059804320","value":898823}},"8c44164a76344653afb976837f28c827":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94ab633305d549ef8bc17f29bac705c4","placeholder":"​","style":"IPY_MODEL_ad1afb8442c2466b916ff85f0b0d1bb6","value":" 878k/878k [00:01&lt;00:00, 1.21MB/s]"}},"af9378a1f484417c997d4f0614339043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d259ec8fde54f928571a1e09d109ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb08c71d29cc481b85e486db1e6774dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01175928d4a4e32aee372a65c237a5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46d61dd445a458f9234728059804320":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94ab633305d549ef8bc17f29bac705c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad1afb8442c2466b916ff85f0b0d1bb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8c5aeae458445b4b79f5573c326634b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4906ebe754d440c2a9ffe296113cc840","IPY_MODEL_de462303a85847f8b8d03383dc7b0346","IPY_MODEL_68bc4932c06b48e1a916ad7c087ddf10"],"layout":"IPY_MODEL_a742ccf181ba48289620e5fc60010f0d"}},"4906ebe754d440c2a9ffe296113cc840":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73ce937de9544beb99f6f16dc2dc6826","placeholder":"​","style":"IPY_MODEL_188bbd843e824190adff3b59c6d70141","value":"Downloading: 100%"}},"de462303a85847f8b8d03383dc7b0346":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e732507ff74c4ab597723998b217b7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64b2aa9378274dd6847ee5b8ee5c9fde","value":456318}},"68bc4932c06b48e1a916ad7c087ddf10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_792d268933144a009f0d7bb84192eabe","placeholder":"​","style":"IPY_MODEL_a8584c1b80554b4b80edcb56804f388c","value":" 446k/446k [00:00&lt;00:00, 637kB/s]"}},"a742ccf181ba48289620e5fc60010f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ce937de9544beb99f6f16dc2dc6826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"188bbd843e824190adff3b59c6d70141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9e732507ff74c4ab597723998b217b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64b2aa9378274dd6847ee5b8ee5c9fde":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"792d268933144a009f0d7bb84192eabe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8584c1b80554b4b80edcb56804f388c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf4c8528e32e409186fd1c376aefd506":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aab5c1fe44fe4133a0ac24fcce0abef2","IPY_MODEL_a6813ab8390748bea95093102880801e","IPY_MODEL_604c836839e842a0a46e0e5824dc4093"],"layout":"IPY_MODEL_e759565714d442819b894481f3e2f998"}},"aab5c1fe44fe4133a0ac24fcce0abef2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68ba3f61f12e458d8d61c1ee6b961c08","placeholder":"​","style":"IPY_MODEL_efb60bac86314ff2b8ed60bd5f2e6139","value":"Downloading: 100%"}},"a6813ab8390748bea95093102880801e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0a7a0765804289a4ee0f6dcb0dc229","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_387dc2a7565342b880eecdbf58b3c3a3","value":481}},"604c836839e842a0a46e0e5824dc4093":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efd513122a9a4c2aa6228c2f96da93bb","placeholder":"​","style":"IPY_MODEL_e5e5d6093dbc4c83a4ce5cd3d625879e","value":" 481/481 [00:00&lt;00:00, 11.2kB/s]"}},"e759565714d442819b894481f3e2f998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ba3f61f12e458d8d61c1ee6b961c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb60bac86314ff2b8ed60bd5f2e6139":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef0a7a0765804289a4ee0f6dcb0dc229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"387dc2a7565342b880eecdbf58b3c3a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efd513122a9a4c2aa6228c2f96da93bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5e5d6093dbc4c83a4ce5cd3d625879e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2186313,"sourceType":"datasetVersion","datasetId":1312443}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install pytorch-transformers\n","import pandas as pd\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import RobertaModel, RobertaTokenizer\n","from transformers import RobertaForSequenceClassification, RobertaConfig\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtMptSyQccep","executionInfo":{"status":"ok","timestamp":1658743816862,"user_tz":-330,"elapsed":31198,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"13126d7a-d60c-48ef-a12e-33af45c9d175","execution":{"iopub.status.busy":"2024-04-21T12:56:05.939035Z","iopub.execute_input":"2024-04-21T12:56:05.939361Z","iopub.status.idle":"2024-04-21T12:56:43.134308Z","shell.execute_reply.started":"2024-04-21T12:56:05.939338Z","shell.execute_reply":"2024-04-21T12:56:43.133334Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nCollecting pytorch-transformers\n  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (1.26.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (4.66.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (2023.12.25)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from pytorch-transformers) (0.2.0)\nCollecting sacremoses (from pytorch-transformers)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch-transformers) (2024.2.0)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch-transformers)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-transformers) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-transformers) (0.6.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-transformers) (2024.2.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->pytorch-transformers) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->pytorch-transformers) (1.4.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch-transformers) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch-transformers) (1.16.0)\nDownloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses, botocore, pytorch-transformers\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.69\n    Uninstalling botocore-1.34.69:\n      Successfully uninstalled botocore-1.34.69\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.165 pytorch-transformers-1.2.0 sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pw9FbBoPmgjk","executionInfo":{"status":"ok","timestamp":1713711984426,"user_tz":-330,"elapsed":22206,"user":{"displayName":"Priyanka Israni","userId":"07224247261387411096"}},"outputId":"63898086-01f7-4c83-d763-c0f8b0ba762a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Anuj_Depression_detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHhRUedlmg76","executionInfo":{"status":"ok","timestamp":1713711984426,"user_tz":-330,"elapsed":5,"user":{"displayName":"Priyanka Israni","userId":"07224247261387411096"}},"outputId":"da9ab72f-75a6-4bba-d1c7-44fb512ba733"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Anuj_Depression_detection\n"]}]},{"cell_type":"markdown","source":["## Loading  data"],"metadata":{"id":"clq5V-4vcceq"}},{"cell_type":"code","source":["source_url = \"sentiment_tweets3.csv\"\n","df = pd.read_csv(source_url)\n"],"metadata":{"id":"PwYWYYXCccer","executionInfo":{"status":"ok","timestamp":1713712055935,"user_tz":-330,"elapsed":715,"user":{"displayName":"Priyanka Israni","userId":"07224247261387411096"}},"execution":{"iopub.status.busy":"2024-04-21T12:56:43.154497Z","iopub.execute_input":"2024-04-21T12:56:43.154894Z","iopub.status.idle":"2024-04-21T12:56:43.216504Z","shell.execute_reply.started":"2024-04-21T12:56:43.154862Z","shell.execute_reply":"2024-04-21T12:56:43.215804Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:43.217481Z","iopub.execute_input":"2024-04-21T12:56:43.217746Z","iopub.status.idle":"2024-04-21T12:56:43.236062Z","shell.execute_reply.started":"2024-04-21T12:56:43.217723Z","shell.execute_reply":"2024-04-21T12:56:43.235232Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"t46qLE5sMJCK","executionInfo":{"status":"ok","timestamp":1713712057044,"user_tz":-330,"elapsed":689,"user":{"displayName":"Priyanka Israni","userId":"07224247261387411096"}},"outputId":"56f66dea-632f-4c18-9200-063103ac3720"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Index                                 message to examine  \\\n","0    106  just had a real good moment. i missssssssss hi...   \n","1    217         is reading manga  http://plurk.com/p/mzp1e   \n","2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n","3    288  @lapcat Need to send 'em to my accountant tomo...   \n","4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n","\n","   label (depression result)  \n","0                          0  \n","1                          0  \n","2                          0  \n","3                          0  \n","4                          0  "],"text/html":["\n","  <div id=\"df-8391f263-5a54-4a75-852c-acb3ff8bdc41\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Index</th>\n","      <th>message to examine</th>\n","      <th>label (depression result)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>106</td>\n","      <td>just had a real good moment. i missssssssss hi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>217</td>\n","      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>220</td>\n","      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>288</td>\n","      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>540</td>\n","      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8391f263-5a54-4a75-852c-acb3ff8bdc41')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8391f263-5a54-4a75-852c-acb3ff8bdc41 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8391f263-5a54-4a75-852c-acb3ff8bdc41');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-31ea2057-c5e5-4f30-9262-914fd2632f7b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31ea2057-c5e5-4f30-9262-914fd2632f7b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-31ea2057-c5e5-4f30-9262-914fd2632f7b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10314,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 261688,\n        \"min\": 106,\n        \"max\": 802313,\n        \"num_unique_values\": 10314,\n        \"samples\": [\n          251196,\n          504883,\n          787069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message to examine\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10282,\n        \"samples\": [\n          \"@Thorpeland No signal is the message that comes up on most monitors here when it's on but has no source. \",\n          \"1. The emotional ride of #perimenopause is ROUGH. I woke up fine, but then felt anger, irritation, just a feeling of wanting to break out, then fell down into a pit of depression. Man, the depression is frustrating and it definitely feels hormonal. I've been working on nutrition.\",\n          \"@dean2105 Stress-free is the way to be \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label (depression result)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df.groupby([\"label (depression result)\"]).size()"],"metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:43.237007Z","iopub.execute_input":"2024-04-21T12:56:43.237239Z","iopub.status.idle":"2024-04-21T12:56:43.248923Z","shell.execute_reply.started":"2024-04-21T12:56:43.237218Z","shell.execute_reply":"2024-04-21T12:56:43.248073Z"},"trusted":true,"id":"xezNnm3QMJCL","outputId":"cf82bd0a-de56-42ff-ecca-4c03d01d5f9c"},"execution_count":null,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"label (depression result)\n0    8000\n1    2314\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":["## Data Preprocessing"],"metadata":{"id":"8-8exyvRcces"}},{"cell_type":"code","source":["#from transformers import RobertaTokenizer\n","\n","tokenizer =  RobertaTokenizer.from_pretrained(\"roberta-base\")"],"metadata":{"_kg_hide-input":true,"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["c1e400d73b7d474b997009634e55de6f","66cdb1449b2f4543af72123e6e8bc8b8","1f0f52e07e3346589ba9b664d62aa432","8c44164a76344653afb976837f28c827","af9378a1f484417c997d4f0614339043","1d259ec8fde54f928571a1e09d109ec2","fb08c71d29cc481b85e486db1e6774dc","d01175928d4a4e32aee372a65c237a5b","f46d61dd445a458f9234728059804320","94ab633305d549ef8bc17f29bac705c4","ad1afb8442c2466b916ff85f0b0d1bb6","a8c5aeae458445b4b79f5573c326634b","4906ebe754d440c2a9ffe296113cc840","de462303a85847f8b8d03383dc7b0346","68bc4932c06b48e1a916ad7c087ddf10","a742ccf181ba48289620e5fc60010f0d","73ce937de9544beb99f6f16dc2dc6826","188bbd843e824190adff3b59c6d70141","e9e732507ff74c4ab597723998b217b7","64b2aa9378274dd6847ee5b8ee5c9fde","792d268933144a009f0d7bb84192eabe","a8584c1b80554b4b80edcb56804f388c","cf4c8528e32e409186fd1c376aefd506","aab5c1fe44fe4133a0ac24fcce0abef2","a6813ab8390748bea95093102880801e","604c836839e842a0a46e0e5824dc4093","e759565714d442819b894481f3e2f998","68ba3f61f12e458d8d61c1ee6b961c08","efb60bac86314ff2b8ed60bd5f2e6139","ef0a7a0765804289a4ee0f6dcb0dc229","387dc2a7565342b880eecdbf58b3c3a3","efd513122a9a4c2aa6228c2f96da93bb","e5e5d6093dbc4c83a4ce5cd3d625879e","f1cbb45d69cb4f30a8abf63d52b93f9f","0a994818fd5044b782ccc15531c1cb49","3ef55de6ecd5487a8bf79b299f0319df","b85ac6f69c86469b872a81e10124725b","8b48553f8cc54e31b94c91cd204b9bda"]},"id":"-AbIzHH_cces","executionInfo":{"status":"ok","timestamp":1658743859470,"user_tz":-330,"elapsed":8824,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"a49ecc05-d5a8-40c0-b244-c0045692f7d5","execution":{"iopub.status.busy":"2024-04-21T12:56:43.250044Z","iopub.execute_input":"2024-04-21T12:56:43.250301Z","iopub.status.idle":"2024-04-21T12:56:45.171218Z","shell.execute_reply.started":"2024-04-21T12:56:43.250280Z","shell.execute_reply":"2024-04-21T12:56:45.170138Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1cbb45d69cb4f30a8abf63d52b93f9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a994818fd5044b782ccc15531c1cb49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ef55de6ecd5487a8bf79b299f0319df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b85ac6f69c86469b872a81e10124725b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b48553f8cc54e31b94c91cd204b9bda"}},"metadata":{}}]},{"cell_type":"code","source":["\n","sample = 'Hey my name is RoBERTa'\n","# truncation : if it is True then we allow bert to truncated every sequence it's length is higher then max_length\n","# return_tensors : the type of tensors that will be returned (as we are using pytorch then we set \"pt\")\n","bert_input  = tokenizer(sample,padding=\"max_length\",max_length=15,truncation=True,return_tensors=\"pt\")\n","\n"],"metadata":{"id":"dIdneqW2cceu","execution":{"iopub.status.busy":"2024-04-21T12:56:45.172423Z","iopub.execute_input":"2024-04-21T12:56:45.172693Z","iopub.status.idle":"2024-04-21T12:56:45.189299Z","shell.execute_reply.started":"2024-04-21T12:56:45.172672Z","shell.execute_reply":"2024-04-21T12:56:45.188564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(bert_input[\"input_ids\"])\n","# input_ids are the id representation of each token\n","# we can decode these inputs to get the original sequence\n","print(tokenizer.decode(bert_input[\"input_ids\"][0] ))\n","# the code 102 is for the [SEP] token and the 0 is for [PAD] token"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlBGhU6Qcceu","executionInfo":{"status":"ok","timestamp":1658743864257,"user_tz":-330,"elapsed":4820,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"e366be38-b6cf-42df-f7d5-60a558b84245","execution":{"iopub.status.busy":"2024-04-21T12:56:45.190330Z","iopub.execute_input":"2024-04-21T12:56:45.190606Z","iopub.status.idle":"2024-04-21T12:56:45.339828Z","shell.execute_reply.started":"2024-04-21T12:56:45.190584Z","shell.execute_reply":"2024-04-21T12:56:45.338971Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"tensor([[    0, 13368,   127,   766,    16,  3830, 11126, 38495,     2,     1,\n             1,     1,     1,     1,     1]])\n<s>Hey my name is RoBERTa</s><pad><pad><pad><pad><pad><pad>\n","output_type":"stream"}]},{"cell_type":"code","source":["print(bert_input[\"attention_mask\"])\n","# the attention_mask identified whether the token is a real word or just a token padding\n","# it's 1 for the real words, the CLS and the SEP tokens, and for the pad token is 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq59rPHjccev","executionInfo":{"status":"ok","timestamp":1658743900775,"user_tz":-330,"elapsed":616,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"fb4dc81d-1d31-4053-bb0c-7b4f6d8bc08f","execution":{"iopub.status.busy":"2024-04-21T12:56:45.343898Z","iopub.execute_input":"2024-04-21T12:56:45.344204Z","iopub.status.idle":"2024-04-21T12:56:45.349593Z","shell.execute_reply.started":"2024-04-21T12:56:45.344181Z","shell.execute_reply":"2024-04-21T12:56:45.348631Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n","output_type":"stream"}]},{"cell_type":"code","source":["df.info()"],"metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:45.350705Z","iopub.execute_input":"2024-04-21T12:56:45.351020Z","iopub.status.idle":"2024-04-21T12:56:45.371546Z","shell.execute_reply.started":"2024-04-21T12:56:45.350997Z","shell.execute_reply":"2024-04-21T12:56:45.370664Z"},"trusted":true,"id":"vrDkHWSAMJCM","outputId":"3d929f2d-31e7-4ea9-99fe-869004409f41"},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10314 entries, 0 to 10313\nData columns (total 3 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   Index                      10314 non-null  int64 \n 1   message to examine         10314 non-null  object\n 2   label (depression result)  10314 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 241.9+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### Dataset Class\n","\n","Now that we know which are the ouputs of our Roberta tokenizer we are going to build a Dataset Class for our depression Dataset"],"metadata":{"id":"w-gT1QQKccew"}},{"cell_type":"code","source":["from transformers import RobertaTokenizer\n","import torch\n","import numpy as np\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        # Extract labels from the DataFrame\n","        self.labels = df[\"label\"].values\n","\n","        # Tokenize texts using RobertaTokenizer\n","        self.texts = [tokenizer.encode_plus(text, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\") for text in df[\"text\"]]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.texts[idx], self.labels[idx]\n","\n",""],"metadata":{"id":"OJvdwWsRccew","execution":{"iopub.status.busy":"2024-04-21T12:56:45.372569Z","iopub.execute_input":"2024-04-21T12:56:45.372903Z","iopub.status.idle":"2024-04-21T12:56:45.604612Z","shell.execute_reply.started":"2024-04-21T12:56:45.372864Z","shell.execute_reply":"2024-04-21T12:56:45.603798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now after creating the Dataset Class let's split our dataset into train,validation and test sets\n","\n","* training set contains : 80%\n","* test and validation contains : 10% each"],"metadata":{"id":"5ahpVcCmccex"}},{"cell_type":"code","source":["df_train, df_valid,df_test = np.split(df.sample(frac=1,random_state=42),[int(.8*len(df)), int(.9*len(df))])\n","\n"],"metadata":{"id":"m6eClKYZccex","execution":{"iopub.status.busy":"2024-04-21T12:56:45.605763Z","iopub.execute_input":"2024-04-21T12:56:45.606085Z","iopub.status.idle":"2024-04-21T12:56:45.620551Z","shell.execute_reply.started":"2024-04-21T12:56:45.606058Z","shell.execute_reply":"2024-04-21T12:56:45.619565Z"},"trusted":true,"outputId":"8e414d59-0569-441f-ea16-b3697dd109c0"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}]},{"cell_type":"code","source":["df_train.info()"],"metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:45.621865Z","iopub.execute_input":"2024-04-21T12:56:45.622232Z","iopub.status.idle":"2024-04-21T12:56:45.632965Z","shell.execute_reply.started":"2024-04-21T12:56:45.622202Z","shell.execute_reply":"2024-04-21T12:56:45.632080Z"},"trusted":true,"id":"pSeM5gSkMJCN","outputId":"c177ee1e-e18b-4eff-8c99-74dfc5426d24"},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 8251 entries, 2458 to 8488\nData columns (total 3 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   Index                      8251 non-null   int64 \n 1   message to examine         8251 non-null   object\n 2   label (depression result)  8251 non-null   int64 \ndtypes: int64(2), object(1)\nmemory usage: 257.8+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":["df_valid.info()"],"metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:45.634076Z","iopub.execute_input":"2024-04-21T12:56:45.634639Z","iopub.status.idle":"2024-04-21T12:56:45.646675Z","shell.execute_reply.started":"2024-04-21T12:56:45.634608Z","shell.execute_reply":"2024-04-21T12:56:45.645906Z"},"trusted":true,"id":"OYv9HP_AMJCN","outputId":"346d0d3c-ea6d-4d31-a14b-aaab44a130f0"},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1031 entries, 5607 to 6783\nData columns (total 3 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   Index                      1031 non-null   int64 \n 1   message to examine         1031 non-null   object\n 2   label (depression result)  1031 non-null   int64 \ndtypes: int64(2), object(1)\nmemory usage: 32.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":["class RoBertaClassifier(torch.nn.Module):\n","    def __init__(self,dropout=0.5):\n","        super(RoBertaClassifier,self).__init__()\n","        self.bert=RobertaModel.from_pretrained(\"roberta-base\")\n","        self.dropout = torch.nn.Dropout(dropout)\n","        # bert output a vector of size 768\n","        self.lin = torch.nn.Linear(768,5)\n","        self.relu = torch.nn.ReLU()\n","    def forward(self,input_id,mask, return_dict):\n","        # as output, the bert model give us first the embedding vector of all the tokens of the sequence\n","        # second we get the embedding vector of the CLS token.\n","        # fot a classification task it's enough to use this embedding for our classifier\n","        _,pooled_output = self.bert(input_ids= input_id,attention_mask = mask,return_dict = return_dict)\n","        dropout_output = self.dropout(pooled_output)\n","        linear_output  = self.lin(dropout_output)\n","        final_layer = self.relu(linear_output)\n","\n","        return final_layer\n",""],"metadata":{"id":"v4Znl1u9ccey","execution":{"iopub.status.busy":"2024-04-21T14:01:14.864081Z","iopub.execute_input":"2024-04-21T14:01:14.864774Z","iopub.status.idle":"2024-04-21T14:01:14.872224Z","shell.execute_reply.started":"2024-04-21T14:01:14.864744Z","shell.execute_reply":"2024-04-21T14:01:14.871258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training  "],"metadata":{"id":"IQ6MvOSqccey"}},{"cell_type":"code","source":["# we are creating a standard pytorch training loop\n","from torch.utils.data import Dataset, DataLoader\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        self.labels = df[\"label (depression result)\"].values\n","        self.texts = [tokenizer.encode_plus(text, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\") for text in df[\"message to examine\"]]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.texts[idx], self.labels[idx]\n","def train(model, train_data, val_data, learning_rate, epochs=5):\n","    #creating a custom Dataset objects using the training and validation data\n","    train, val = CustomDataset(train_data), CustomDataset(val_data)\n","    #creating dataloaders\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n","\n","    if use_cuda:\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","                #print(f\"the train input : {train_input}\")\n","                #print(f\"train label : {train_label}\")\n","\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","    #             print(input_id.shape)\n","\n","                # get the predictions\n","                output = model(input_id, mask,return_dict=False)\n","\n","                #the output is a vector of 5 values (categs)\n","    #             print(output)\n","    #             print(\"the output shape is\" ,  output.shape)\n","    #             print(train_label)\n","\n","                batch_loss = criterion(output, train_label)\n","                total_loss_train += batch_loss.item()\n","\n","                acc = (output.argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","                # updating the Gradient Descent and Backpropagation operation\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            # now we evaluate on the validation data\n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask, return_dict=False)\n","\n","                    batch_loss = criterion(output, val_label)\n","                    total_loss_val += batch_loss.item()\n","\n","                    acc = (output.argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","\n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n","                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n","                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n","\n"],"metadata":{"id":"jZKthYhsccez","execution":{"iopub.status.busy":"2024-04-21T14:01:20.583827Z","iopub.execute_input":"2024-04-21T14:01:20.584215Z","iopub.status.idle":"2024-04-21T14:01:20.600466Z","shell.execute_reply.started":"2024-04-21T14:01:20.584186Z","shell.execute_reply":"2024-04-21T14:01:20.599540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","EPOCHS = 5\n","model = RoBertaClassifier()\n","learning_rate = 1e-5\n"],"metadata":{"scrolled":true,"id":"tuuE0-x2ccez","execution":{"iopub.status.busy":"2024-04-21T14:01:26.424669Z","iopub.execute_input":"2024-04-21T14:01:26.425401Z","iopub.status.idle":"2024-04-21T14:01:26.899310Z","shell.execute_reply.started":"2024-04-21T14:01:26.425370Z","shell.execute_reply":"2024-04-21T14:01:26.898401Z"},"trusted":true,"outputId":"a138e55a-ddf2-460c-f016-d7041268435b"},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":["train(model, df_train, df_valid, learning_rate, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYa5dGcEvP6j","executionInfo":{"status":"ok","timestamp":1658746958974,"user_tz":-330,"elapsed":638695,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"70480eeb-1aa6-4ae7-b271-d6c6424abb16","execution":{"iopub.status.busy":"2024-04-21T14:01:34.526118Z","iopub.execute_input":"2024-04-21T14:01:34.526829Z","iopub.status.idle":"2024-04-21T14:47:29.635875Z","shell.execute_reply.started":"2024-04-21T14:01:34.526799Z","shell.execute_reply":"2024-04-21T14:47:29.634836Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 4126/4126 [08:51<00:00,  7.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.014                 | Train Accuracy:  0.993                 | Val Loss:  0.008                 | Val Accuracy:  0.995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4126/4126 [08:49<00:00,  7.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.002                 | Train Accuracy:  0.999                 | Val Loss:  0.005                 | Val Accuracy:  0.999\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4126/4126 [08:49<00:00,  7.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.002                 | Train Accuracy:  0.999                 | Val Loss:  0.005                 | Val Accuracy:  0.999\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4126/4126 [08:49<00:00,  7.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.001                 | Train Accuracy:  1.000                 | Val Loss:  0.005                 | Val Accuracy:  0.999\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4126/4126 [08:49<00:00,  7.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 | Train Loss:  0.001                 | Train Accuracy:  1.000                 | Val Loss:  0.005                 | Val Accuracy:  0.999\n","output_type":"stream"}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxmtBv8c42Ud","executionInfo":{"status":"ok","timestamp":1658744809954,"user_tz":-330,"elapsed":825,"user":{"displayName":"Priyanka Israni","userId":"10459553611843066072"}},"outputId":"122be914-926d-46af-a6e1-8aae4ee3a6f1","execution":{"iopub.status.busy":"2024-04-21T13:56:58.654213Z","iopub.execute_input":"2024-04-21T13:56:58.654868Z","iopub.status.idle":"2024-04-21T13:56:58.661296Z","shell.execute_reply.started":"2024-04-21T13:56:58.654836Z","shell.execute_reply":"2024-04-21T13:56:58.660393Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"RoBertaClassifier(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.5, inplace=False)\n  (lin): Linear(in_features=768, out_features=5, bias=True)\n  (relu): ReLU()\n)\n","output_type":"stream"}]}]}